{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c497b7a2-64c1-44b2-8044-e7997bcb21fc",
   "metadata": {},
   "source": [
    "# Open RiOMar HEALPix_Zarr data  \n",
    "\n",
    "## Prerequisites\n",
    "1. . Install:\n",
    "```bash\n",
    "pip install xdggs\n",
    "```\n",
    "\n",
    "\n",
    "## What this notebook does\n",
    "- Loads the Healpix_ Zarr riomar data \n",
    "- visualise with xdggs\n",
    "\n",
    "\n",
    "## Steps\n",
    "1.\t**Setup & load inputs**\n",
    "\n",
    "Load the  Zarr file \n",
    "\n",
    "2.\t**visualise **\n",
    "\n",
    "\n",
    "\n",
    "## Output dataset conventions\n",
    "- meta data shoudl be updated to aligne fair practice? \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf86e0c-20ba-494f-a0e6-ebe16d9b05bd",
   "metadata": {},
   "source": [
    "## Step 1 — Setup & load zarr file "
   ]
  },
  {
   "cell_type": "raw",
   "id": "db05ff1d-c1ca-417a-8547-e76136c4e67c",
   "metadata": {},
   "source": [
    "##on HPC\n",
    "import os\n",
    "import psutil\n",
    "from dask.distributed import Client, LocalCluster\n",
    "\n",
    "from pathlib import Path\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import xdggs\n",
    "import healpix_geo\n",
    "\n",
    "\n",
    "# pick a fast local path on the compute node\n",
    "local_dir = (\n",
    " \"/tmp\"\n",
    ")\n",
    "local_dir = str(Path(local_dir) / \"dask-scratch\")\n",
    "print(\"Using Dask local_directory:\", local_dir)\n",
    "\n",
    "\n",
    "print(\"=== Starting local Dask cluster (auto-sized) ===\")\n",
    "\n",
    "cpu = os.cpu_count() or 1\n",
    "total_gb = psutil.virtual_memory().total / (1024**3)\n",
    "\n",
    "# Good “use most, but not all” defaults:\n",
    "n_workers = cpu                   # ~1 worker per CPU core\n",
    "threads_per_worker = 1            # best for numpy-heavy compute\n",
    "memory_limit_gb = (total_gb * 0.85) / n_workers  # leave ~15% headroom\n",
    "memory_limit = f\"{memory_limit_gb:.2f}GB\"\n",
    "n_workers=32\n",
    "cluster = LocalCluster(\n",
    "    n_workers=n_workers,\n",
    "#    threads_per_worker=threads_per_worker,\n",
    "    processes=True,\n",
    "    memory_limit=memory_limit,\n",
    "    local_directory=local_dir,   # <--- THIS FIXES THE WARNING\n",
    "    dashboard_address=\":8787\",\n",
    ")\n",
    "client = Client(cluster)\n",
    "\n",
    "print(\"Dask dashboard:\", client.dashboard_link)\n",
    "\n",
    "print(\"\\n=== Dask cluster resources ===\")\n",
    "info = client.scheduler_info()\n",
    "workers = info[\"workers\"]\n",
    "\n",
    "total_threads = sum(w[\"nthreads\"] for w in workers.values())\n",
    "total_mem_gb = sum(w[\"memory_limit\"] for w in workers.values()) / (1024**3)\n",
    "\n",
    "print(f\"Workers: {len(workers)}\")\n",
    "print(f\"Total threads: {total_threads}\")\n",
    "print(f\"Total memory limit: {total_mem_gb:.2f} GB\")\n",
    "\n",
    "# Optional: per-worker details\n",
    "#for addr, w in workers.items():\n",
    " #   print(f\"- {addr}: nthreads={w['nthreads']}, mem_limit={w['memory_limit']/1e9:.2f} GB »)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348f524a-bf93-4586-9b59-9ba15e916322",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import xdggs\n",
    "from dask.distributed import Client, LocalCluster\n",
    "cluster = LocalCluster()\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab01346-fa97-4c34-b010-8d2767ea217f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "zarr_hp_file_path = 'https://data-fair2adapt.ifremer.fr/riomar-zarr_tina/small_hp.zarr'\n",
    "zarr_hp_file_path = '/scale/riomar-zarr_tina/small_hp.zarr'\n",
    "zarr_hp_file_path = 'https://data-fair2adapt.ifremer.fr/riomar-zarr_tina/test3.zarr'\n",
    "zarr_hp_file_path = './riomar-zarr_tina/test3.zarr'\n",
    "\n",
    "ds = xr.open_zarr(zarr_hp_file_path)\n",
    "#ds = ds.persist().sortby(\"time_counter\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1e2f46-e6a5-472a-a801-af06c747e42f",
   "metadata": {},
   "source": [
    "## Step 2 -- resample the data and visualise\n",
    "\n",
    "\n",
    "### 2.1 plot daily mean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de6abea-494b-49b3-bd6c-8a60db84357f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make time monotonic (required for resample)\n",
    "\n",
    "# Daily mean\n",
    "ds_mean_daily = ds.resample(time_counter=\"1D\").mean(keep_attrs=True)\n",
    "ds_mean_daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f613e0e-101c-4ead-9337-59edf97b58e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    ds_mean_daily.compute()\n",
    "    .pipe(xdggs.decode)\n",
    "    .dggs.assign_latlon_coords()\n",
    "    .dggs.explore(alpha=0.3)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc865ec-ee5c-42f1-adab-4afa25e44a06",
   "metadata": {},
   "source": [
    "### 2.2 plot time series of one point   \n",
    "\n",
    "chose one point and make time series plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a1ebc7-9a92-4310-8c2c-31c16568a096",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 1) Midpoint of your bbox\n",
    "lon_min, lon_max = -2.8, -1.97333\n",
    "lat_min, lat_max = 47.04367, 47.31558\n",
    "\n",
    "lon_mid = (lon_min + lon_max) / 2.0\n",
    "lat_mid = (lat_min + lat_max) / 2.0\n",
    "\n",
    "print(\"midpoint:\", lon_mid, lat_mid)\n",
    "\n",
    "# 2) Pick up the level from the dataset's cell_ids attribute\n",
    "level = ds.cell_ids.attrs['level']\n",
    "\n",
    "# Common attribute keys people use — adjust if your file uses another name\n",
    "\n",
    "\n",
    "print(\"HEALPix level:\", level)\n",
    "\n",
    "# 3) Compute the Helix cell_id for that lon/lat using healpix_geo\n",
    "#    (function names vary a bit between packages/versions; try the usual one)\n",
    "import healpix_geo as hpg\n",
    "\n",
    "cell_id = hpg.nested.lonlat_to_healpix(lon_mid, lat_mid, depth=level,ellipsoid= \"WGS84\")\n",
    "\n",
    "print(\"HEALPix cell_id:\", cell_id)\n",
    "\n",
    "# 4) Select that cell from ds\n",
    "# If cell_ids is a coordinate along dimension \"cell_ids\", this should work:\n",
    "ds_point=ds.sel(cell_ids=cell_id).pipe(xdggs.decode).dggs.assign_latlon_coords().compute()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87093cd1-9d91-4405-83ba-b9a75704ce83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ds_point.zeta.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af184e63-3041-4e91-80b5-b4e4c960fa9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.savefig(\"zeta.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef97d2a-54e5-4961-8997-3826298d11ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
